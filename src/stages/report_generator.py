"""
HTML æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆäº§å“çº§çš„å¤„ç†æŠ¥å‘Š
"""

import json
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime
from collections import Counter

from ..core.models import Chunk, QualityLevel


class ReportGenerator:
    """
    HTML æŠ¥å‘Šç”Ÿæˆå™¨
    ç”ŸæˆåŒ…å«ç»Ÿè®¡ä¿¡æ¯ã€è´¨é‡åˆ†æã€æ¨èå‚æ•°çš„å¯è§†åŒ–æŠ¥å‘Š
    """
    
    def __init__(self, output_dir: Path):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.report_dir = self.output_dir / "report"
        self.report_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_report(
        self,
        chunks: List[Chunk],
        rejected_chunks: List[Dict[str, Any]],
        stats: Dict[str, Any],
        config: Dict[str, Any]
    ):
        """
        ç”Ÿæˆå®Œæ•´çš„ HTML æŠ¥å‘Š
        
        Args:
            chunks: æ¥å—çš„ chunk åˆ—è¡¨
            rejected_chunks: æ‹’ç»çš„ chunk åˆ—è¡¨ï¼ˆåŒ…å«åŸå› ï¼‰
            stats: ç»Ÿè®¡ä¿¡æ¯
            config: è¿è¡Œé…ç½®
        """
        html = self._build_html(chunks, rejected_chunks, stats, config)
        
        output_file = self.report_dir / "report.html"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html)
        
        return output_file
    
    def _build_html(
        self,
        chunks: List[Chunk],
        rejected_chunks: List[Dict[str, Any]],
        stats: Dict[str, Any],
        config: Dict[str, Any]
    ) -> str:
        """æ„å»º HTML å†…å®¹"""
        
        # åˆ†ææ•°æ®
        analysis = self._analyze_data(chunks, rejected_chunks, stats)
        
        html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAGSmith Processing Report</title>
    <style>
        {self._get_css()}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ”¨ RAGSmith Processing Report</h1>
            <p class="subtitle">Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </header>
        
        {self._build_summary_section(stats, config)}
        {self._build_strategy_section(config)}
        {self._build_chunks_section(analysis)}
        {self._build_quality_section(analysis)}
        {self._build_rejection_section(analysis)}
        {self._build_llm_section(analysis, stats)}
        {self._build_recommendations_section(analysis)}
        
        <footer>
            <p>Generated by RAGSmith v2.0 | <a href="https://github.com/gxdbox/ragsmith">GitHub</a></p>
        </footer>
    </div>
</body>
</html>"""
        
        return html
    
    def _get_css(self) -> str:
        """è·å– CSS æ ·å¼"""
        return """
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            border-radius: 10px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .subtitle {
            opacity: 0.9;
            font-size: 1.1em;
        }
        
        .section {
            background: white;
            padding: 30px;
            margin-bottom: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .section h2 {
            color: #667eea;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #f0f0f0;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        
        .stat-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        
        .stat-card .label {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 5px;
        }
        
        .stat-card .value {
            font-size: 2em;
            font-weight: bold;
            color: #333;
        }
        
        .stat-card .unit {
            color: #999;
            font-size: 0.9em;
        }
        
        .chart {
            margin: 20px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
        }
        
        .bar {
            display: flex;
            align-items: center;
            margin: 10px 0;
        }
        
        .bar-label {
            width: 150px;
            font-weight: 500;
        }
        
        .bar-fill {
            flex: 1;
            height: 30px;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            border-radius: 4px;
            position: relative;
            margin: 0 10px;
        }
        
        .bar-value {
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            color: white;
            font-weight: bold;
        }
        
        .recommendation {
            background: #e7f3ff;
            border-left: 4px solid #2196F3;
            padding: 15px;
            margin: 10px 0;
            border-radius: 4px;
        }
        
        .recommendation h4 {
            color: #2196F3;
            margin-bottom: 5px;
        }
        
        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 10px 0;
            border-radius: 4px;
        }
        
        .success {
            background: #d4edda;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 10px 0;
            border-radius: 4px;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        
        th {
            background: #f8f9fa;
            font-weight: 600;
            color: #667eea;
        }
        
        tr:hover {
            background: #f8f9fa;
        }
        
        footer {
            text-align: center;
            padding: 20px;
            color: #666;
            margin-top: 40px;
        }
        
        footer a {
            color: #667eea;
            text-decoration: none;
        }
        
        .badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.85em;
            font-weight: 600;
        }
        
        .badge-success {
            background: #d4edda;
            color: #155724;
        }
        
        .badge-warning {
            background: #fff3cd;
            color: #856404;
        }
        
        .badge-info {
            background: #d1ecf1;
            color: #0c5460;
        }
        """
    
    def _analyze_data(
        self,
        chunks: List[Chunk],
        rejected_chunks: List[Dict[str, Any]],
        stats: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†ææ•°æ®å¹¶ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        
        # Chunk é•¿åº¦åˆ†å¸ƒ
        token_counts = [c.token_count for c in chunks]
        length_distribution = {
            "0-200": sum(1 for t in token_counts if t < 200),
            "200-500": sum(1 for t in token_counts if 200 <= t < 500),
            "500-800": sum(1 for t in token_counts if 500 <= t < 800),
            "800-1200": sum(1 for t in token_counts if 800 <= t < 1200),
            "1200+": sum(1 for t in token_counts if t >= 1200),
        }
        
        # è´¨é‡åˆ†å¸ƒ
        quality_distribution = Counter(
            c.llm_quality.value if c.llm_quality else "not_evaluated"
            for c in chunks
        )
        
        # æ‹’ç»åŸå› ç»Ÿè®¡
        rejection_reasons = Counter(
            r.get('reason', 'unknown') for r in rejected_chunks
        )
        
        # è§„åˆ™å¾—åˆ†åˆ†å¸ƒ
        rule_scores = [c.rule_score for c in chunks if c.rule_score is not None]
        avg_rule_score = sum(rule_scores) / len(rule_scores) if rule_scores else 0
        
        # LLM ç½®ä¿¡åº¦åˆ†å¸ƒ
        llm_confidences = [c.llm_confidence for c in chunks if c.llm_confidence is not None]
        avg_llm_confidence = sum(llm_confidences) / len(llm_confidences) if llm_confidences else 0
        
        return {
            "length_distribution": length_distribution,
            "quality_distribution": quality_distribution,
            "rejection_reasons": rejection_reasons,
            "avg_token_count": sum(token_counts) / len(token_counts) if token_counts else 0,
            "avg_rule_score": avg_rule_score,
            "avg_llm_confidence": avg_llm_confidence,
            "total_tokens": sum(token_counts),
        }
    
    def _build_summary_section(self, stats: Dict[str, Any], config: Dict[str, Any]) -> str:
        """æ„å»ºæ‘˜è¦éƒ¨åˆ†"""
        return f"""
        <div class="section">
            <h2>ğŸ“Š Processing Summary</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="label">Source File</div>
                    <div class="value">{stats.get('source_file', 'N/A')}</div>
                </div>
                <div class="stat-card">
                    <div class="label">Total Pages</div>
                    <div class="value">{stats.get('total_pages', 0)}</div>
                    <div class="unit">pages</div>
                </div>
                <div class="stat-card">
                    <div class="label">Accepted Chunks</div>
                    <div class="value">{stats.get('accepted_chunks', 0)}</div>
                    <div class="unit">chunks</div>
                </div>
                <div class="stat-card">
                    <div class="label">Rejected Chunks</div>
                    <div class="value">{stats.get('rejected_chunks', 0)}</div>
                    <div class="unit">chunks</div>
                </div>
                <div class="stat-card">
                    <div class="label">Processing Time</div>
                    <div class="value">{stats.get('duration_seconds', 0) / 60:.1f}</div>
                    <div class="unit">minutes</div>
                </div>
                <div class="stat-card">
                    <div class="label">Acceptance Rate</div>
                    <div class="value">{stats.get('accepted_chunks', 0) / max(stats.get('total_chunks', 1), 1) * 100:.1f}%</div>
                </div>
            </div>
        </div>
        """
    
    def _build_strategy_section(self, config: Dict[str, Any]) -> str:
        """æ„å»ºç­–ç•¥ä¿¡æ¯éƒ¨åˆ†"""
        strategy_name = config.get('metadata', {}).get('strategy', 'unknown')
        strategy_display = config.get('metadata', {}).get('strategy_display_name', strategy_name)
        
        return f"""
        <div class="section">
            <h2>âš™ï¸ Strategy Configuration</h2>
            <div class="success">
                <h4>Strategy: {strategy_display}</h4>
                <p>Chunk Size: {config.get('chunk', {}).get('size', 'N/A')} tokens | 
                   Overlap: {config.get('chunk', {}).get('overlap', 'N/A')} tokens | 
                   LLM Validation: {'Enabled' if config.get('llm', {}).get('enabled') else 'Disabled'}</p>
            </div>
        </div>
        """
    
    def _build_chunks_section(self, analysis: Dict[str, Any]) -> str:
        """æ„å»º chunk åˆ†æéƒ¨åˆ†"""
        dist = analysis['length_distribution']
        max_count = max(dist.values()) if dist.values() else 1
        
        bars = ""
        for label, count in dist.items():
            width = (count / max_count * 100) if max_count > 0 else 0
            bars += f"""
            <div class="bar">
                <div class="bar-label">{label} tokens</div>
                <div class="bar-fill" style="width: {width}%">
                    <span class="bar-value">{count}</span>
                </div>
            </div>
            """
        
        return f"""
        <div class="section">
            <h2>ğŸ“ Chunk Length Distribution</h2>
            <div class="chart">
                {bars}
            </div>
            <p><strong>Average Token Count:</strong> {analysis['avg_token_count']:.0f} tokens</p>
            <p><strong>Total Tokens:</strong> {analysis['total_tokens']:,} tokens</p>
        </div>
        """
    
    def _build_quality_section(self, analysis: Dict[str, Any]) -> str:
        """æ„å»ºè´¨é‡åˆ†æéƒ¨åˆ†"""
        dist = analysis['quality_distribution']
        
        rows = ""
        for quality, count in dist.most_common():
            badge_class = {
                'excellent': 'badge-success',
                'good': 'badge-success',
                'acceptable': 'badge-warning',
                'poor': 'badge-warning',
                'not_evaluated': 'badge-info'
            }.get(quality, 'badge-info')
            
            rows += f"""
            <tr>
                <td><span class="badge {badge_class}">{quality}</span></td>
                <td>{count}</td>
                <td>{count / sum(dist.values()) * 100:.1f}%</td>
            </tr>
            """
        
        return f"""
        <div class="section">
            <h2>âœ¨ Quality Analysis</h2>
            <table>
                <thead>
                    <tr>
                        <th>Quality Level</th>
                        <th>Count</th>
                        <th>Percentage</th>
                    </tr>
                </thead>
                <tbody>
                    {rows}
                </tbody>
            </table>
            <p><strong>Average Rule Score:</strong> {analysis['avg_rule_score']:.3f}</p>
            {f"<p><strong>Average LLM Confidence:</strong> {analysis['avg_llm_confidence']:.3f}</p>" if analysis['avg_llm_confidence'] > 0 else ""}
        </div>
        """
    
    def _build_rejection_section(self, analysis: Dict[str, Any]) -> str:
        """æ„å»ºæ‹’ç»åŸå› åˆ†æéƒ¨åˆ†"""
        reasons = analysis['rejection_reasons']
        
        if not reasons:
            return """
            <div class="section">
                <h2>ğŸš« Rejection Analysis</h2>
                <div class="success">
                    <p>No chunks were rejected. Excellent quality!</p>
                </div>
            </div>
            """
        
        rows = ""
        for reason, count in reasons.most_common():
            rows += f"""
            <tr>
                <td>{reason}</td>
                <td>{count}</td>
                <td>{count / sum(reasons.values()) * 100:.1f}%</td>
            </tr>
            """
        
        return f"""
        <div class="section">
            <h2>ğŸš« Rejection Analysis</h2>
            <table>
                <thead>
                    <tr>
                        <th>Reason</th>
                        <th>Count</th>
                        <th>Percentage</th>
                    </tr>
                </thead>
                <tbody>
                    {rows}
                </tbody>
            </table>
        </div>
        """
    
    def _build_llm_section(self, analysis: Dict[str, Any], stats: Dict[str, Any]) -> str:
        """æ„å»º LLM ä½¿ç”¨åˆ†æéƒ¨åˆ†"""
        llm_calls = stats.get('llm_calls', 0)
        
        if llm_calls == 0:
            return """
            <div class="section">
                <h2>ğŸ¤– LLM Usage</h2>
                <div class="warning">
                    <p>LLM validation was not used in this processing.</p>
                </div>
            </div>
            """
        
        # ä¼°ç®—æˆæœ¬ï¼ˆå‡è®¾æ¯æ¬¡è°ƒç”¨ 0.001 å…ƒï¼‰
        estimated_cost = llm_calls * 0.001
        
        return f"""
        <div class="section">
            <h2>ğŸ¤– LLM Usage</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="label">Total LLM Calls</div>
                    <div class="value">{llm_calls}</div>
                    <div class="unit">calls</div>
                </div>
                <div class="stat-card">
                    <div class="label">Estimated Cost</div>
                    <div class="value">Â¥{estimated_cost:.2f}</div>
                </div>
            </div>
            <p style="margin-top: 15px; color: #666; font-size: 0.9em;">
                * Cost estimation based on local LLM usage. Actual cost may vary.
            </p>
        </div>
        """
    
    def _build_recommendations_section(self, analysis: Dict[str, Any]) -> str:
        """æ„å»ºæ¨èå‚æ•°éƒ¨åˆ†"""
        avg_tokens = analysis['avg_token_count']
        
        # æ ¹æ®å¹³å‡ token æ•°æ¨è RAG å‚æ•°
        recommended_top_k = max(3, min(10, int(1000 / avg_tokens)))
        recommended_chunk_size = int(avg_tokens * 0.8)
        
        return f"""
        <div class="section">
            <h2>ğŸ’¡ RAG Recommendations</h2>
            
            <div class="recommendation">
                <h4>Recommended top_k</h4>
                <p>Based on your average chunk size ({avg_tokens:.0f} tokens), we recommend setting <code>top_k={recommended_top_k}</code> for retrieval.</p>
            </div>
            
            <div class="recommendation">
                <h4>Recommended Chunk Size for Re-chunking</h4>
                <p>If you need to re-process with different chunk size, consider <code>chunk_size={recommended_chunk_size}</code> tokens.</p>
            </div>
            
            <div class="recommendation">
                <h4>Vector Database Selection</h4>
                <p>For {analysis['total_tokens']:,} total tokens:</p>
                <ul style="margin-top: 10px;">
                    <li><strong>FAISS:</strong> Good for &lt;1M tokens, local deployment</li>
                    <li><strong>Milvus:</strong> Good for &gt;1M tokens, distributed deployment</li>
                    <li><strong>PGVector:</strong> Good if you already use PostgreSQL</li>
                </ul>
            </div>
        </div>
        """
